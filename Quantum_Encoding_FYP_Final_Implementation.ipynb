{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNlDiCWcPLyjXy97mxbpm+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anushka091922/FYP-NLP-Relevance-/blob/main/Quantum_Encoding_FYP_Final_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Securely load and verify API keys stored in a .env file using\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kyzHCOT_KFqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rShs2O_UJuBw"
      },
      "outputs": [],
      "source": [
        "# Creating the .env file with the required environment variables\n",
        "with open(\".env\", \"w\") as file:\n",
        "    file.write(\"\"\"\n",
        "LANGCHAIN_TRACING_V2=true\n",
        "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
        "LANGCHAIN_PROJECT=advanced-rag\n",
        "LANGCHAIN_API_KEY=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\n",
        "GROQ_API_KEY=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\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install python-dotenv\n",
        "!pip install python-dotenv\n",
        "\n",
        "# Import necessary modules\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv(\".env\")\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
        "os.environ['LANGCHAIN_PROJECT'] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n"
      ],
      "metadata": {
        "id": "2bqNgSw5KKZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if environment variables are set\n",
        "print(os.getenv(\"LANGCHAIN_API_KEY\"))\n",
        "print(os.getenv(\"GROQ_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "wznth58EKKbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and check the contents of the .env file\n",
        "with open(\".env\", \"r\") as file:\n",
        "    print(file.read())  # This will print the content of the .env file to verify it\n"
      ],
      "metadata": {
        "id": "sQIWmfRTKKdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv())"
      ],
      "metadata": {
        "id": "Eyeo67piKKhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'advanced-rag'\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")"
      ],
      "metadata": {
        "id": "SpWHiPjaKKjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieve DuckDuckGo search results using requests, parse them with BeautifulSoup, and save the data to a CSV file."
      ],
      "metadata": {
        "id": "RHb0iwmBKY-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n",
        "!pip install langchain_groq\n",
        "!pip install faiss-cpu\n",
        "!pip install transformers\n",
        "!pip install requests beautifulsoup4 googlesearch-python pandas\n",
        "!pip install requests beautifulsoup4 pandas\n"
      ],
      "metadata": {
        "id": "Bk4Q9D0_KKk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_duckduckgo_results(query):\n",
        "    url = f\"https://duckduckgo.com/html/?q={query}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    results = []\n",
        "    for a in soup.find_all('a', class_='result__a'):\n",
        "        link = a['href']\n",
        "        results.append(link)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "vFUKokrnKKmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd  # Ensure pandas is imported\n",
        "import re\n",
        "\n",
        "def fetch_duckduckgo_results(query, num_results=100):  # Set num_results to 100\n",
        "    url = f\"https://duckduckgo.com/html/?q={query}\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
        "    results = []\n",
        "\n",
        "    while len(results) < num_results:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Loop through the search result links\n",
        "        for a in soup.find_all('a', class_='result__a'):\n",
        "            link = a['href']\n",
        "            content = fetch_page_content(link)\n",
        "            results.append((link, content))\n",
        "            if len(results) >= num_results:\n",
        "                break\n",
        "\n",
        "        # Look for the next page of results\n",
        "        next_page = soup.find('a', class_='result--more__btn')\n",
        "        if next_page:\n",
        "            url = f\"https://duckduckgo.com{next_page['href']}\"\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return results[:num_results]\n",
        "\n",
        "def fetch_page_content(url):\n",
        "    try:\n",
        "        # Send a request to fetch the content of the result page\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            page_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            # Extract the main content of the page (adjust this as necessary)\n",
        "            content = page_soup.get_text(strip=True)\n",
        "            return content\n",
        "        else:\n",
        "            return f\"Failed to retrieve content from {url}. Status code: {response.status_code}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching content: {str(e)}\"\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    # Save data into a CSV file\n",
        "    df = pd.DataFrame(data, columns=['URL', 'Content'])\n",
        "    df.to_csv(filename, index=False)  # Save as .csv file\n",
        "\n",
        "# Main program to fetch results\n",
        "query = input(\"Enter the search query: \")\n",
        "\n",
        "# Sanitize query to use as a filename (remove spaces and special characters)\n",
        "sanitized_query = re.sub(r'[^a-zA-Z0-9]', '_', query)  #here we are Replacing non-alphanumeric characters with '_'\n",
        "filename = f\"{sanitized_query}__100.csv\"  # Dynamically create filename for 100 results\n",
        "\n",
        "results = fetch_duckduckgo_results(query, num_results=100)  # Fetch 100 results\n",
        "\n",
        "if not results:\n",
        "    print(\"No results found!\")\n",
        "else:\n",
        "    # Saving the results to a CSV file\n",
        "    save_to_csv(results, filename)\n",
        "    print(f\"Results saved to '{filename}'\")\n",
        "\n",
        "    # Optionally, print the results to check\n",
        "    for idx, (url, content) in enumerate(results, start=1):\n",
        "        print(f\"\\nResult {idx}: {url}\")\n",
        "\n",
        "        # Split content into lines and print the first 1500 lines\n",
        "        lines = content.splitlines()  # Split content by lines\n",
        "        first_lines = \"\\n\".join(lines[:2500])  # Get the first 1500 lines\n",
        "        print(f\"Content (first 1500 lines):\\n{first_lines}...\")"
      ],
      "metadata": {
        "id": "N4dya7j-KKoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utilize a dedicated model to decompose a primary query into refined sub-queries and retrieve corresponding search results."
      ],
      "metadata": {
        "id": "puvpUD6FKjIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Decomposition Chain Setup\n",
        "template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question.\n",
        "The goal is to break down the input into a set of sub-problems that can be answered in isolation.\n",
        "Generate exactly 5 search queries related to: {question}\n",
        "Output ONLY the plain queries separated by newlines (NO numbering, quotes, or markdown):\"\"\"\n",
        "prompt_decomposition = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Updated to use Llama3 70B production model\n",
        "llm = ChatGroq(temperature=0, model=\"llama3-70b-8192\")\n",
        "generate_queries_decomposition = (\n",
        "    prompt_decomposition\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        "    | (lambda x: [q.strip() for q in x.split(\"\\n\") if q.strip()])\n",
        ")\n",
        "\n",
        "# Web Scraping Functions\n",
        "def clean_query(query):\n",
        "    return re.sub(r'^\\d+[\\.\\s]*', '', query).strip(' \"\\'')\n",
        "\n",
        "def fetch_duckduckgo_results(query, num_results=10):\n",
        "    url = f\"https://duckduckgo.com/html/?q={requests.utils.quote(query)}\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36\"}\n",
        "    results = []\n",
        "\n",
        "    response = requests.get(url, headers=headers, timeout=15)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    for a in soup.find_all('a', href=True):\n",
        "        href = a['href']\n",
        "        if \"/l/?uddg=\" in href:\n",
        "            match = re.search(r\"uddg=([^&]+)\", href)\n",
        "            if match:\n",
        "                link = requests.utils.unquote(match.group(1))\n",
        "                content = fetch_page_content(link)\n",
        "                results.append((link, content))\n",
        "                if len(results) >= num_results:\n",
        "                    break\n",
        "    return results\n",
        "\n",
        "def fetch_page_content(url, retries=2):\n",
        "    for _ in range(retries + 1):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            if response.status_code == 200:\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                return soup.get_text(strip=True, separator=' ')[:50000]\n",
        "            return f\"HTTP Error {response.status_code}\"\n",
        "        except Exception as e:\n",
        "            if _ == retries:\n",
        "                return f\"Error: {str(e)}\"\n",
        "            time.sleep(1)\n",
        "\n",
        "def sanitize_filename(text):\n",
        "    return re.sub(r'[^a-zA-Z0-9]', '_', text)[:150]\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    df = pd.DataFrame(data, columns=['URL', 'Content'])\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    original_query = input(\"Enter your main question: \")\n",
        "\n",
        "    sub_questions = generate_queries_decomposition.invoke({\"question\": original_query})\n",
        "\n",
        "    print(f\"\\nGenerated Sub-Questions:\")\n",
        "    for idx, q in enumerate(sub_questions, 1):\n",
        "        print(f\"{idx}. {q}\")\n",
        "\n",
        "    for question in sub_questions:\n",
        "        print(f\"\\nProcessing: {question}\")\n",
        "        results = fetch_duckduckgo_results(question, num_results=100)\n",
        "\n",
        "        if results:\n",
        "            safe_name = sanitize_filename(question) + \"__100.csv\"\n",
        "            save_to_csv(results, safe_name)\n",
        "            print(f\"Saved {len(results)} results to {safe_name}\")\n",
        "            time.sleep(2)\n",
        "        else:\n",
        "            print(f\"No results found for: {question}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "SohRLK87KKqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from langchain import hub\n",
        "import re\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "!pip install --upgrade langchain\n",
        "!pip install tiktoken\n"
      ],
      "metadata": {
        "id": "g0q_OldiKKsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CSV Data Loading and Chunk Splitting"
      ],
      "metadata": {
        "id": "43L4bHfOKtnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash\n",
        "!pip install matplotlib scipy pennylane sentence-transformers\n",
        "import os\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output, State\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "from sklearn.cluster import KMeans\n",
        "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
        "import textwrap\n",
        "\n",
        "# Function to load all CSV files from a given directory\n",
        "def load_csv_files(folder_path=\".\"):\n",
        "    documents = []\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".csv\"):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            print(f\"Loading file: {file_path}\")\n",
        "            df = pd.read_csv(file_path)\n",
        "            for _, row in df.iterrows():\n",
        "                if 'Content' in df.columns and 'URL' in df.columns:\n",
        "                    url, content = row['URL'], row['Content']\n",
        "                    documents.append(Document(page_content=content, metadata={\"source\": url}))\n",
        "    return documents\n",
        "\n",
        "# Initialize the text splitter using tiktoken encoder\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50\n",
        ")\n"
      ],
      "metadata": {
        "id": "yG2NAfNqKKue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents from CSV files in the current directory\n",
        "documents = load_csv_files(folder_path=\".\")\n",
        "\n",
        "if not documents:\n",
        "    print(\"No documents to process!\")\n",
        "else:\n",
        "    # Split the documents into chunks\n",
        "    splits = text_splitter.split_documents(documents)\n",
        "    print(f\"Number of chunks created: {len(splits)}\")\n"
      ],
      "metadata": {
        "id": "cHDVPkI7KKwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3D Visualization of Document Chunks using TSNE and Dash"
      ],
      "metadata": {
        "id": "f0wRoD46K160"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_chunks_3d(splits):\n",
        "    \"\"\"Advanced 3D Visualization of Document Chunks\"\"\"\n",
        "    # Generate embeddings using the BGE model\n",
        "    model_name = \"BAAI/bge-small-en\"\n",
        "    model_kwargs = {\"device\": \"cpu\"}\n",
        "    encode_kwargs = {\"normalize_embeddings\": True}\n",
        "    embedding_model = HuggingFaceBgeEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs\n",
        "    )\n",
        "\n",
        "    # Create embeddings matrix from document chunks\n",
        "    texts = [doc.page_content for doc in splits]\n",
        "    embeddings = np.array(embedding_model.embed_documents(texts))\n",
        "\n",
        "    # Build DataFrame with chunk metadata and previews\n",
        "    df = pd.DataFrame({\n",
        "        \"source\": [doc.metadata[\"source\"] for doc in splits],\n",
        "        \"content\": [doc.page_content for doc in splits],\n",
        "        \"chunk_length\": [len(doc.page_content) for doc in splits],\n",
        "        \"chunk_preview\": [textwrap.shorten(doc.page_content, width=50) for doc in splits]\n",
        "    })\n",
        "\n",
        "    # Add dimensionality reduction projections\n",
        "    df['pca'] = list(PCA(n_components=3).fit_transform(embeddings))\n",
        "    df['tsne'] = list(TSNE(n_components=3).fit_transform(embeddings))\n",
        "    df['umap'] = list(umap.UMAP(n_components=3).fit_transform(embeddings))\n",
        "\n",
        "    # Initialize the Dash app\n",
        "    app = dash.Dash(__name__)\n",
        "\n",
        "    # Layout with dropdowns, slider, search box, and 3D graph\n",
        "    app.layout = html.Div([\n",
        "        html.Div([\n",
        "            dcc.Dropdown(\n",
        "                id='projection-method',\n",
        "                options=[\n",
        "                    {'label': 'PCA', 'value': 'pca'},\n",
        "                    {'label': 't-SNE', 'value': 'tsne'},\n",
        "                    {'label': 'UMAP', 'value': 'umap'}\n",
        "                ],\n",
        "                value='pca',\n",
        "                style={'width': '200px'}\n",
        "            ),\n",
        "            dcc.Dropdown(\n",
        "                id='color-scheme',\n",
        "                options=[\n",
        "                    {'label': 'By Source', 'value': 'source'},\n",
        "                    {'label': 'By Length', 'value': 'chunk_length'},\n",
        "                    {'label': 'By Cluster', 'value': 'cluster'}\n",
        "                ],\n",
        "                value='source',\n",
        "                style={'width': '200px'}\n",
        "            ),\n",
        "            dcc.Slider(\n",
        "                id='cluster-slider',\n",
        "                min=2,\n",
        "                max=10,\n",
        "                step=1,\n",
        "                value=5,\n",
        "                marks={i: str(i) for i in range(2, 11)}\n",
        "            ),\n",
        "            dcc.Input(\n",
        "                id='search-box',\n",
        "                type='text',\n",
        "                placeholder='Search chunks...',\n",
        "                style={'width': '300px'}\n",
        "            )\n",
        "        ], style={'padding': '20px', 'display': 'flex', 'gap': '20px', 'flexWrap': 'wrap'}),\n",
        "\n",
        "        dcc.Graph(id='3d-scatter', style={'height': '70vh'}),\n",
        "\n",
        "        html.Div([\n",
        "            html.Div(id='chunk-details', style={\n",
        "                'padding': '20px',\n",
        "                'border': '1px solid #ddd',\n",
        "                'marginTop': '20px',\n",
        "                'maxHeight': '200px',\n",
        "                'overflowY': 'auto'\n",
        "            }),\n",
        "            html.Div(id='cluster-summary', style={\n",
        "                'padding': '20px',\n",
        "                'marginTop': '20px'\n",
        "            })\n",
        "        ])\n",
        "    ])\n",
        "\n",
        "    # Callback to update the 3D graph based on user selections\n",
        "    @app.callback(\n",
        "        Output('3d-scatter', 'figure'),\n",
        "        [Input('projection-method', 'value'),\n",
        "         Input('color-scheme', 'value'),\n",
        "         Input('cluster-slider', 'value')]\n",
        "    )\n",
        "    def update_graph(projection_method, color_scheme, n_clusters):\n",
        "        if color_scheme == 'cluster':\n",
        "            clusters = KMeans(n_clusters=n_clusters).fit_predict(embeddings)\n",
        "            df['cluster'] = clusters\n",
        "        coords = np.array(df[projection_method].tolist())\n",
        "        fig = px.scatter_3d(\n",
        "            df,\n",
        "            x=coords[:, 0],\n",
        "            y=coords[:, 1],\n",
        "            z=coords[:, 2],\n",
        "            color=color_scheme,\n",
        "            hover_data=['source', 'chunk_preview'],\n",
        "            labels={'color': color_scheme.capitalize()},\n",
        "            title=f\"3D Chunk Visualization - {projection_method.upper()}\"\n",
        "        )\n",
        "        fig.update_traces(\n",
        "            marker=dict(size=4, opacity=0.8),\n",
        "            selector=dict(mode='markers')\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    # Callback to update the chunk details when a point is clicked or searched\n",
        "    @app.callback(\n",
        "        Output('chunk-details', 'children'),\n",
        "        [Input('3d-scatter', 'clickData'),\n",
        "         Input('search-box', 'value')]\n",
        "    )\n",
        "    def update_details(clickData, search_query):\n",
        "        ctx = dash.callback_context\n",
        "        trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
        "        if trigger_id == 'search-box' and search_query:\n",
        "            matches = df[df['content'].str.contains(search_query, case=False)]\n",
        "            if not matches.empty:\n",
        "                return html.Div([\n",
        "                    html.H5(f\"Search Results ({len(matches)} found)\"),\n",
        "                    *[html.P(f\"{row['source']}: {row['chunk_preview']}\") for _, row in matches.iterrows()]\n",
        "                ])\n",
        "            return \"No matching chunks found.\"\n",
        "        if clickData:\n",
        "            index = clickData['points'][0]['pointIndex']\n",
        "            return html.Div([\n",
        "                html.H5(f\"Source: {df.iloc[index]['source']}\"),\n",
        "                html.P(f\"Length: {df.iloc[index]['chunk_length']} characters\"),\n",
        "                html.Hr(),\n",
        "                html.Pre(df.iloc[index]['content'])\n",
        "            ])\n",
        "        return \"Click a point or search to view chunk details\"\n",
        "\n",
        "    # Callback to update cluster summary when clustering is selected\n",
        "    @app.callback(\n",
        "        Output('cluster-summary', 'children'),\n",
        "        [Input('color-scheme', 'value'),\n",
        "         Input('cluster-slider', 'value')]\n",
        "    )\n",
        "    def update_cluster_summary(color_scheme, n_clusters):\n",
        "        if color_scheme == 'cluster':\n",
        "            cluster_counts = df['cluster'].value_counts().reset_index()\n",
        "            cluster_counts.columns = ['Cluster', 'Count']\n",
        "            return html.Div([\n",
        "                html.H5(\"Cluster Summary\"),\n",
        "                html.Table([\n",
        "                    html.Thead(html.Tr([html.Th(\"Cluster\"), html.Th(\"Count\")])),\n",
        "                    html.Tbody([\n",
        "                        html.Tr([html.Td(row['Cluster']), html.Td(row['Count'])]) for _, row in cluster_counts.iterrows()\n",
        "                    ])\n",
        "                ])\n",
        "            ])\n",
        "        return \"\"\n",
        "\n",
        "    return app\n",
        "\n",
        "# Run the Dash visualization app\n",
        "viz_app = visualize_chunks_3d(splits)\n",
        "viz_app.run(debug=True)\n",
        "\n",
        "# Optionally, print each chunk's content and metadata\n",
        "for idx, chunk in enumerate(splits):\n",
        "    print(f\"\\nChunk {idx + 1}:\")\n",
        "    print(f\"Content: {chunk.page_content[:500]}...\")  # Print the first 500 characters\n",
        "    print(f\"Metadata: {chunk.metadata}\")\n"
      ],
      "metadata": {
        "id": "-FF7tqYKLAQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embed the query and document chunks using HuggingFace embeddings.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "faIxynV_K8f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "# Initialize the HuggingFaceBgeEmbeddings\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# Embedding a query (assuming 'query' is the search query you want to embed)\n",
        "query_result = hf_embeddings.embed_query(query)\n",
        "\n",
        "# Extract text content from the chunked Document objects\n",
        "documents_text = [doc.page_content for doc in splits]  # Extracting text content from the chunks\n",
        "\n",
        "# Embedding the documents\n",
        "document_result = hf_embeddings.embed_documents(documents_text)  # Embedding the extracted text\n",
        "\n",
        "# Get the length of the query result embedding\n",
        "print(f\"Length of the query embedding: {len(query_result)}\")\n",
        "\n",
        "# Optional: Checking the length of the document embeddings if needed\n",
        "print(f\"Number of document embeddings: {len(document_result)}\")\n"
      ],
      "metadata": {
        "id": "6_G_hKflKKyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantum-Inspired Semantic Search Implementation –\n",
        "\n",
        "### Query Decomposition and Data Retrieval\n",
        "The process begins by decomposing a primary query into targeted sub-queries. Each sub-query fetches relevant search results from DuckDuckGo, with the retrieved data stored as CSV files. Instead of processing entire documents, the system segments them into context-rich chunks.\n",
        "\n",
        "### Quantum Semantic Field Representation\n",
        "Drawing inspiration from Quantum Semantic Field Theory, each document chunk is treated as an \"excitation\" in a high-dimensional vector space. In quantum mechanics, a state is described by a wave function $\\psi(x)$, often expressed as:\n",
        "$$\n",
        "\\boxed{\\Large \\psi(x) = \\sum_{i} a_i \\phi_i(x)}\n",
        "$$\n",
        "Here, $a_i$ are amplitude coefficients representing the contribution of basis functions $\\phi_i(x)$. Similarly, our system uses amplitude encoding to transform each document chunk into a quantum-inspired embedding, where these amplitudes capture the nuanced semantic features.\n",
        "\n",
        "### Embedding and Semantic Ranking\n",
        "The encoded embeddings, derived from the amplitude values, encapsulate the probabilistic semantic distribution of each chunk. This allows the system to rank document chunks based on their semantic relevance, effectively prioritizing the most meaningful content for refined search results.\n",
        "\n",
        "### Physics-Inspired Approach\n",
        "By applying quantum mechanical principles—such as state superposition and amplitude probability distributions—to text embeddings, the system leverages a novel, high-fidelity semantic ranking mechanism. This results in a sophisticated semantic search experience that transcends traditional keyword matching.\n",
        "\n",
        "### Summary\n",
        "This comprehensive approach seamlessly integrates query decomposition, data retrieval, quantum-inspired document chunking, and amplitude encoding to deliver an enriched and innovative semantic search solution.\n"
      ],
      "metadata": {
        "id": "WitoUg7ZLHXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane --upgrade\n",
        "!pip install dash-daq\n",
        "!pip install umap-learn plotly numpy"
      ],
      "metadata": {
        "id": "ave_OWPDKK06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: QUANTUM-INSPIRED AMPLITUDE ENCODING WITH CONTENT DISPLAY\n",
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def quantum_amplitude_encoding(splits):\n",
        "    print(\"\\n=== STARTING QUANTUM AMPLITUDE ENCODING ===\")\n",
        "\n",
        "    # 1. Generate semantic embeddings with sentence-transformers\n",
        "    print(\"\\nGenerating semantic embeddings using sentence-transformers...\")\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    docs_text = [doc.page_content for doc in splits]\n",
        "\n",
        "    # Display sample document content\n",
        "    print(\"\\nSample document content preview:\")\n",
        "    for i in range(min(3, len(splits))):\n",
        "        print(f\"Document {i+1}: {splits[i].page_content[:80]}...\")\n",
        "\n",
        "    # Generate and normalize embeddings\n",
        "    classical_embeddings = model.encode(docs_text,\n",
        "                                      normalize_embeddings=True,\n",
        "                                      convert_to_numpy=True)\n",
        "    print(f\"\\nGenerated {len(classical_embeddings)} classical embeddings\")\n",
        "    print(f\"Embedding dimension: {classical_embeddings.shape[1]}\")\n",
        "\n",
        "    # 2. Prepare for quantum encoding\n",
        "    original_dim = classical_embeddings.shape[1]\n",
        "    next_pow2 = int(2**np.ceil(np.log2(original_dim)))\n",
        "    n_qubits = int(np.log2(next_pow2))\n",
        "    print(f\"\\nQuantum configuration:\")\n",
        "    print(f\"Original dimension: {original_dim} (Sentence Transformer output)\")\n",
        "    print(f\"Next power of 2: {next_pow2} (using {n_qubits} qubits)\")\n",
        "    print(f\"Each document will be represented by {2**n_qubits} quantum amplitudes\")\n",
        "\n",
        "    # 3. Pad vectors to next power of two dimensions\n",
        "    padded_embeddings = np.zeros((len(classical_embeddings), next_pow2))\n",
        "    padded_embeddings[:, :original_dim] = classical_embeddings\n",
        "    print(f\"\\nPadded embeddings shape: {padded_embeddings.shape}\")\n",
        "\n",
        "    # 4. Set up PennyLane quantum node\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def amplitude_encoder(state):\n",
        "        qml.AmplitudeEmbedding(features=state,\n",
        "                             wires=range(n_qubits),\n",
        "                             normalize=False,\n",
        "                             pad_with=0.0)\n",
        "        return qml.state()\n",
        "\n",
        "    # 5. Process all documents with content display\n",
        "    print(\"\\nEncoding documents into quantum states:\")\n",
        "    quantum_states = []\n",
        "    for idx, emb in enumerate(padded_embeddings):\n",
        "        doc_content = splits[idx].page_content\n",
        "        truncated_content = (doc_content[:75] + '...') if len(doc_content) > 75 else doc_content\n",
        "\n",
        "        # Progress update with content snippet every 50 documents\n",
        "        if idx % 50 == 0:\n",
        "            print(f\"\\nProcessing document {idx+1}/{len(padded_embeddings)}\")\n",
        "            print(f\"Content snippet: {truncated_content}\")\n",
        "            print(f\"Original embedding dimensions: {original_dim} → Quantum dimensions: {next_pow2}\")\n",
        "\n",
        "        # Convert to complex amplitudes\n",
        "        norm = np.linalg.norm(emb)\n",
        "        complex_emb = emb.astype(np.complex128)\n",
        "        state = amplitude_encoder(complex_emb)\n",
        "        quantum_states.append(state)\n",
        "\n",
        "        # Detailed display for first 3 documents\n",
        "        if idx < 3:\n",
        "            print(f\"\\n=== DOCUMENT {idx+1} DETAILED ANALYSIS ===\")\n",
        "            print(f\"Full content: {doc_content}\")\n",
        "            print(\"\\nQuantum State Analysis:\")\n",
        "            print(f\"- State vector shape: {state.shape} (Represents {2**n_qubits} possible quantum states)\")\n",
        "            print(f\"- First 5 amplitudes: {state[:5]}\")\n",
        "            print(\"   These values represent the quantum superposition coefficients for the first 5 basis states\")\n",
        "            print(f\"- Norm check: {np.sum(np.abs(state)**2):.4f} (Must be 1.0 for valid quantum state)\")\n",
        "            print(f\"- Content length: {len(doc_content)} characters\")\n",
        "            print(f\"- First 5 embedding values: {emb[:5]} (Classical input to quantum system)\")\n",
        "\n",
        "    print(\"\\n=== QUANTUM ENCODING COMPLETE ===\")\n",
        "    return quantum_states\n",
        "\n",
        "# Execute the encoding process\n",
        "quantum_excitations = quantum_amplitude_encoding(splits)"
      ],
      "metadata": {
        "id": "zdeUPUOYKK24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import textwrap  # Needed for shortening text previews\n",
        "\n",
        "def quantum_amplitude_encoding(splits):\n",
        "    print(\"\\n=== STARTING QUANTUM-INSPIRED AMPLITUDE ENCODING ===\")\n",
        "    print(\"Objective: Represent documents as quantum state vectors through amplitude encoding\\n\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PHASE 1: SEMANTIC EMBEDDING GENERATION\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"=== PHASE 1: SEMANTIC EMBEDDING GENERATION ===\")\n",
        "    print(\"Using 'all-MiniLM-L6-v2' model from sentence-transformers\")\n",
        "    print(\"Model Details:\")\n",
        "    print(\"- Transformer architecture with 6 layers\")\n",
        "    print(\"- 384-dimensional embedding space\")\n",
        "    print(\"- Normalized L2 outputs\\n\")\n",
        "\n",
        "    # Initialize the SentenceTransformer model for generating embeddings\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    docs_text = [doc.page_content for doc in splits]\n",
        "\n",
        "    print(f\"Processing {len(docs_text)} document chunks:\")\n",
        "    for idx, text in enumerate(docs_text[:3]):  # Show first 3 examples for preview\n",
        "        print(f\"\\nDocument {idx+1} (Preview):\")\n",
        "        print(textwrap.shorten(text, width=150))\n",
        "\n",
        "    print(\"\\nGenerating embeddings with parameters:\")\n",
        "    print(\"- normalize_embeddings=True (L2 normalization)\")\n",
        "    print(\"- convert_to_numpy=True (NumPy array output)\")\n",
        "\n",
        "    # Generate and normalize embeddings using the model\n",
        "    classical_embeddings = model.encode(docs_text,\n",
        "                                      normalize_embeddings=True,\n",
        "                                      convert_to_numpy=True)\n",
        "\n",
        "    print(\"\\n=== EMBEDDING ANALYSIS ===\")\n",
        "    print(f\"Generated {len(classical_embeddings)} embeddings\")\n",
        "    print(f\"Embedding dimension: {classical_embeddings.shape[1]}\")\n",
        "    print(\"\\nFirst embedding vector sample:\")\n",
        "    print(classical_embeddings[0][:10])  # Show first 10 elements of the first embedding\n",
        "    print(\"... (truncated)\")\n",
        "    print(f\"Norm check: {np.linalg.norm(classical_embeddings[0]):.4f} (should be ~1.0)\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PHASE 2: QUANTUM PREPARATION\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n\\n=== PHASE 2: QUANTUM PREPARATION ===\")\n",
        "    original_dim = classical_embeddings.shape[1]\n",
        "    next_pow2 = int(2**np.ceil(np.log2(original_dim)))\n",
        "    n_qubits = int(np.log2(next_pow2))\n",
        "\n",
        "    print(\"Dimensionality Analysis:\")\n",
        "    print(f\"- Original dimension: {original_dim}\")\n",
        "    print(f\"- Next power of 2: {next_pow2}\")\n",
        "    print(f\"- Required qubits: {n_qubits} (2^{n_qubits} = {next_pow2})\")\n",
        "    print(\"\\nQuantum encoding strategy:\")\n",
        "    print(f\"Each {original_dim}D vector will be padded with {next_pow2 - original_dim} zeros\")\n",
        "    print(\"to fit power-of-two dimensions required for qubit register\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Padding the embeddings to power-of-two dimensions\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\nPadding embeddings...\")\n",
        "    padded_embeddings = np.zeros((len(classical_embeddings), next_pow2))\n",
        "    padded_embeddings[:, :original_dim] = classical_embeddings\n",
        "\n",
        "    print(\"\\nPadded Embedding Example (Document 1):\")\n",
        "    print(f\"Original: {original_dim} elements\")\n",
        "    print(f\"Padded: {next_pow2} elements\")\n",
        "    print(\"First 10 elements (original part):\")\n",
        "    print(padded_embeddings[0][:10])\n",
        "    print(\"Last 10 elements (zero padding):\")\n",
        "    print(padded_embeddings[0][-10:])\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PHASE 3: QUANTUM CIRCUIT SETUP\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n\\n=== PHASE 3: QUANTUM CIRCUIT SETUP ===\")\n",
        "    print(\"Creating amplitude encoding circuit with PennyLane\")\n",
        "    print(\"Device: default.qubit (simulator)\")\n",
        "    print(f\"Qubits: {n_qubits} qubit register\")\n",
        "\n",
        "    # Set up the quantum device using PennyLane\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "    # Define a quantum node that embeds a classical vector into a quantum state.\n",
        "    @qml.qnode(dev)\n",
        "    def amplitude_encoder(state):\n",
        "        qml.AmplitudeEmbedding(features=state,\n",
        "                             wires=range(n_qubits),\n",
        "                             normalize=False,  # Embeddings are already normalized\n",
        "                             pad_with=0.0)\n",
        "        return qml.state()\n",
        "\n",
        "    print(\"\\nCircuit diagram:\")\n",
        "    # Removed the unsupported 'expansion_strategy' argument.\n",
        "    print(qml.draw(amplitude_encoder)(padded_embeddings[0]))\n",
        "    print(\"\\nEncoding explanation:\")\n",
        "    print(\"- AmplitudeEmbedding maps classical data to qubit amplitudes\")\n",
        "    print(f\"- {next_pow2}-dimensional vector → {n_qubits}-qubit state\")\n",
        "    print(\"- Each element becomes the probability amplitude for the corresponding basis state\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # PHASE 4: QUANTUM STATE ENCODING\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n\\n=== PHASE 4: QUANTUM STATE ENCODING ===\")\n",
        "    print(f\"Processing {len(padded_embeddings)} documents:\")\n",
        "\n",
        "    quantum_states = []\n",
        "    for idx, emb in enumerate(padded_embeddings):\n",
        "        print(f\"\\n\\n--- Document {idx+1}/{len(padded_embeddings)} ---\")\n",
        "        print(f\"Source: {splits[idx].metadata['source']}\")\n",
        "        print(f\"Content preview: {textwrap.shorten(splits[idx].page_content, width=120)}\")\n",
        "\n",
        "        # Show full processing details for the first 3 documents\n",
        "        if idx < 3:\n",
        "            print(\"\\nPre-Quantum Processing:\")\n",
        "            print(\"1. Original embedding vector (first 10 elements):\")\n",
        "            print(emb[:10])\n",
        "            print(\"... (truncated)\")\n",
        "            print(f\"2. Norm check: {np.linalg.norm(emb):.4f}\")\n",
        "\n",
        "            print(\"3. Converting to complex numbers:\")\n",
        "            complex_emb = emb.astype(np.complex128)\n",
        "            print(f\"Data type: {complex_emb.dtype}\")\n",
        "            print(f\"First element: {complex_emb[0]} (real: {complex_emb[0].real:.4f}, imag: {complex_emb[0].imag:.4f})\")\n",
        "\n",
        "            print(\"\\nQuantum Encoding Process:\")\n",
        "            print(f\"Applying AmplitudeEmbedding to a vector of length {len(complex_emb)}\")\n",
        "            print(f\"Mapping to a {n_qubits}-qubit system (2^{n_qubits} = {2**n_qubits} basis states)\")\n",
        "\n",
        "        # Convert the padded embedding to complex and encode it\n",
        "        complex_emb = emb.astype(np.complex128)\n",
        "        state = amplitude_encoder(complex_emb)\n",
        "        quantum_states.append(state)\n",
        "\n",
        "        if idx < 3:\n",
        "            print(\"\\nPost-Quantum State Analysis:\")\n",
        "            print(f\"State vector shape: {state.shape}\")\n",
        "            print(\"First 5 amplitudes:\")\n",
        "            for i, amp in enumerate(state[:5]):\n",
        "                # Display basis state in binary (padded to n_qubits bits) and amplitude\n",
        "                print(f\"|{bin(i)[2:].zfill(n_qubits)}⟩: {amp.real:.4f}{amp.imag:+.4f}j\")\n",
        "            norm_ver = np.sum(np.abs(state)**2)\n",
        "            print(f\"Norm verification: {norm_ver:.4f} (should be 1.0)\")\n",
        "        elif idx % 10 == 0:\n",
        "            print(f\"Document {idx+1} processed - State norm: {np.sum(np.abs(state)**2):.4f}\")\n",
        "\n",
        "    print(\"\\n\\n=== QUANTUM ENCODING COMPLETE ===\")\n",
        "    print(f\"Generated {len(quantum_states)} quantum state vectors\")\n",
        "    print(f\"State vector dimension: {quantum_states[0].shape[0]}\")\n",
        "    print(\"First state metadata:\")\n",
        "    print(f\"- Source: {splits[0].metadata['source']}\")\n",
        "    print(f\"- State norm: {np.sum(np.abs(quantum_states[0])**2):.4f}\")\n",
        "    print(\"- Amplitude sample (first 5):\")\n",
        "    print(quantum_states[0][:5])\n",
        "\n",
        "    return quantum_states\n",
        "\n",
        "# Execute the enhanced encoding process\n",
        "quantum_excitations = quantum_amplitude_encoding(splits)\n"
      ],
      "metadata": {
        "id": "4GLvRrz6KK6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total splits: {len(splits)}\")\n",
        "for i, doc in enumerate(splits[:3]):\n",
        "    print(f\"Doc {i+1} preview:\", doc.page_content[:100])\n"
      ],
      "metadata": {
        "id": "4dkS3F_bKK8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3D visualization"
      ],
      "metadata": {
        "id": "h1PDh5dzLa-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# QUANTUM HOLOGRAPHIC VISUALIZATION SYSTEM\n",
        "import dash\n",
        "from dash import dcc, html, Output, Input, State, dash_table\n",
        "import dash_daq as daq\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from dash.exceptions import PreventUpdate\n",
        "import numpy as np\n",
        "from threading import Thread\n",
        "import queue\n",
        "import umap\n",
        "from sklearn.decomposition import PCA\n",
        "from pennylane import numpy as pnp\n",
        "import textwrap\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pennylane as qml\n",
        "import time\n",
        "\n",
        "class QuantumHologram:\n",
        "    def __init__(self, max_documents=1000):\n",
        "        self.data_stream = queue.Queue(maxsize=100)\n",
        "        self.quantum_fields = {\n",
        "            'state_vectors': [],\n",
        "            'entanglement_graphs': [],\n",
        "            'temporal_states': [],\n",
        "            'hyper_projection': None\n",
        "        }\n",
        "        self.document_universe = []\n",
        "\n",
        "        # Advanced Projection Systems\n",
        "        self.holo_projector = umap.UMAP(\n",
        "            n_components=3,  # Reduced for better 3D visualization\n",
        "            metric='cosine',\n",
        "            n_neighbors=15,\n",
        "            min_dist=0.1\n",
        "        )\n",
        "        self.chrono_projector = PCA(n_components=2)\n",
        "        self.qubit_mesh = None\n",
        "\n",
        "        # Quantum Field Parameters\n",
        "        self.projector_lock = False\n",
        "        self.current_quantum_frame = 0\n",
        "        self.temporal_window = 20\n",
        "        self.hyper_scale = 0.5\n",
        "\n",
        "        # Initialize Holo-Displays\n",
        "        self.phase_space = self._create_holo_space()\n",
        "        self.probability_field = self._create_probability_field()\n",
        "        self.entanglement_web = self._create_entanglement_web()\n",
        "        self.temporal_wave = self._create_temporal_wave()\n",
        "\n",
        "    def _create_holo_space(self):\n",
        "        \"\"\"3D Projection System with Temporal Coloring\"\"\"\n",
        "        fig = go.Figure()\n",
        "        fig.update_layout(\n",
        "            title='3D Quantum Holographic Space',\n",
        "            scene=dict(\n",
        "                xaxis=dict(title='Ψ-X', gridcolor='rgba(0,255,0,0.1)'),\n",
        "                yaxis=dict(title='Ψ-Y', gridcolor='rgba(0,0,255,0.1)'),\n",
        "                zaxis=dict(title='Ψ-Z', gridcolor='rgba(255,0,0,0.1)'),\n",
        "                bgcolor='rgba(0,0,0,1)',\n",
        "                camera=dict(eye=dict(x=1.8, y=1.8, z=0.8))\n",
        "            ),\n",
        "            height=800,\n",
        "            paper_bgcolor='black',\n",
        "            font=dict(color='white'))\n",
        "        return fig\n",
        "\n",
        "    def _create_probability_field(self):\n",
        "        \"\"\"Dynamic Amplitude Flux Visualization\"\"\"\n",
        "        fig = go.Figure()\n",
        "        fig.update_layout(\n",
        "            title='Probability Density Flux',\n",
        "            xaxis=dict(title='Basis State', gridcolor='#2a3f5f'),\n",
        "            yaxis=dict(title='|ψ|²', gridcolor='#2a3f5f'),\n",
        "            height=400,\n",
        "            paper_bgcolor='rgba(0,0,0,0.8)',\n",
        "            plot_bgcolor='rgba(0,0,0,0.8)',\n",
        "            font=dict(color='Red')\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    def _create_entanglement_web(self):\n",
        "        \"\"\"Quantum Entanglement Hypergraph\"\"\"\n",
        "        fig = go.Figure()\n",
        "        fig.update_layout(\n",
        "            title='Qubit Entanglement Hyperstructure',\n",
        "            showlegend=False,\n",
        "            height=600,\n",
        "            xaxis=dict(visible=False),\n",
        "            yaxis=dict(visible=False),\n",
        "            paper_bgcolor='black'\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    def _create_temporal_wave(self):\n",
        "        \"\"\"Temporal State Evolution Display\"\"\"\n",
        "        fig = go.Figure()\n",
        "        fig.update_layout(\n",
        "            title='Temporal State Evolution',\n",
        "            xaxis=dict(title='Time Step', gridcolor='#2a3f5f'),\n",
        "            yaxis=dict(title='State Similarity', gridcolor='#2a3f5f'),\n",
        "            height=400,\n",
        "            paper_bgcolor='rgba(0,0,0,0.8)',\n",
        "            plot_bgcolor='rgba(0,0,0,0.8)',\n",
        "            font=dict(color='white')\n",
        "        )\n",
        "        return fig\n",
        "\n",
        "    def _hyper_project(self, states):\n",
        "        \"\"\"3D projection with UMAP\"\"\"\n",
        "        if len(states) < 5:\n",
        "            return np.zeros((len(states), 3))\n",
        "        return self.holo_projector.fit_transform(states)\n",
        "\n",
        "    def _render_holo_space(self, view_state):\n",
        "        \"\"\"Render 3D projection\"\"\"\n",
        "        fig = go.Figure(self.phase_space)\n",
        "        if self.quantum_fields['hyper_projection'] is not None:\n",
        "            proj = self.quantum_fields['hyper_projection']\n",
        "            fig.add_trace(go.Scatter3d(\n",
        "                x=proj[:, 0],\n",
        "                y=proj[:, 1],\n",
        "                z=proj[:, 2],\n",
        "                mode='markers',\n",
        "                marker=dict(\n",
        "                    size=8,\n",
        "                    color=np.linspace(0, 1, len(proj)),\n",
        "                    colorscale='Rainbow',\n",
        "                    opacity=0.8\n",
        "                ),\n",
        "                hovertext=[d['text'] for d in self.document_universe]\n",
        "            ))\n",
        "        return fig\n",
        "\n",
        "    def _render_probability_field(self):\n",
        "        \"\"\"Render probability field with actual data\"\"\"\n",
        "        fig = go.Figure(self.probability_field)\n",
        "        if self.quantum_fields['state_vectors']:\n",
        "            last_state = self.quantum_fields['state_vectors'][-1]\n",
        "            fig.add_trace(go.Bar(\n",
        "                x=list(range(len(last_state))),\n",
        "                y=last_state,\n",
        "                marker_color='#14074a'\n",
        "            ))\n",
        "        return fig\n",
        "\n",
        "    def _analyze_quantum_state(self):\n",
        "        \"\"\"Real quantum state analysis\"\"\"\n",
        "        if not self.quantum_fields['state_vectors']:\n",
        "            return [], html.Ul([html.Li(\"No data\")])\n",
        "\n",
        "        last_state = self.quantum_fields['state_vectors'][-1]\n",
        "        matrix_data = [{\n",
        "            'qubit': i,\n",
        "            'zero': last_state[i],\n",
        "            'one': last_state[i+len(last_state)//2] if i+len(last_state)//2 < len(last_state) else 0,\n",
        "            'entanglement': np.mean(last_state)\n",
        "        } for i in range(8)]\n",
        "\n",
        "        consciousness = html.Ul([\n",
        "            html.Li(f\"Document {i+1}: {textwrap.shorten(d['text'], 100)}\")\n",
        "            for i, d in enumerate(self.document_universe[-5:])\n",
        "        ])\n",
        "        return matrix_data, consciousness\n",
        "\n",
        "    def launch_hologram(self):\n",
        "        \"\"\"Activate Quantum Visualization Interface\"\"\"\n",
        "        app = dash.Dash(__name__, suppress_callback_exceptions=True)\n",
        "        app.layout = html.Div([\n",
        "            dcc.Interval(id='interval-update', interval=1000, n_intervals=0),\n",
        "            html.Div([\n",
        "                daq.LEDDisplay(\n",
        "                    id='quantum-state-counter',\n",
        "                    value=\"0000\",\n",
        "                    label=\"Quantum States Rendered\",\n",
        "                    color=\"#00ffaa\"\n",
        "                ),\n",
        "                daq.Knob(\n",
        "                    id='temporal-scale',\n",
        "                    label=\"Temporal Window\",\n",
        "                    value=self.temporal_window,\n",
        "                    max=50,\n",
        "                    color='#ff00ff'\n",
        "                ),\n",
        "                daq.Slider(\n",
        "                    id='hyper-scale',\n",
        "                    min=0.1,\n",
        "                    max=2.0,\n",
        "                    value=self.hyper_scale,\n",
        "                    handleLabel='Hyper Scale'\n",
        "                )\n",
        "            ], style={'position': 'fixed', 'top': 10, 'right': 10, 'zIndex': 1000}),\n",
        "\n",
        "            dcc.Tabs([\n",
        "                dcc.Tab(label='Quantum Hologram', children=[\n",
        "                    dcc.Graph(\n",
        "                        id='holo-display',\n",
        "                        style={'height': '85vh'},\n",
        "                        config={'scrollZoom': True}\n",
        "                    )\n",
        "                ]),\n",
        "                dcc.Tab(label='Quantum Anatomy', children=[\n",
        "                    html.Div([\n",
        "                        dcc.Graph(id='probability-field'),\n",
        "                        dcc.Graph(id='entanglement-web')\n",
        "                    ], style={'display': 'flex'})\n",
        "                ]),\n",
        "                dcc.Tab(label='Temporal Dynamics', children=[\n",
        "                    dcc.Graph(id='temporal-wave')\n",
        "                ])\n",
        "            ]),\n",
        "            html.Div([\n",
        "                html.Div([\n",
        "                    html.H3(\"Quantum State Matrix\"),\n",
        "                    dash_table.DataTable(\n",
        "                        id='quantum-matrix',\n",
        "                        columns=[\n",
        "                            {'name': 'Qubit', 'id': 'qubit'},\n",
        "                            {'name': '|0⟩', 'id': 'zero'},\n",
        "                            {'name': '|1⟩', 'id': 'one'},\n",
        "                            {'name': 'Entanglement', 'id': 'entanglement'}\n",
        "                        ],\n",
        "                        style_table={'height': '200px'},\n",
        "                        style_cell={'backgroundColor': 'white', 'color': 'Blue'}\n",
        "                    )\n",
        "                ], style={'width': '30%'}),\n",
        "                html.Div([\n",
        "                    html.H3(\"Document Consciousness\"),\n",
        "                    html.Div(\n",
        "                        id='quantum-consciousness',\n",
        "                        style={'height': '200px', 'overflowY': 'auto'}\n",
        "                    )\n",
        "                ], style={'width': '70%'})\n",
        "            ], style={'display': 'flex'})\n",
        "        ], style={'backgroundColor': 'white'})\n",
        "\n",
        "        @app.callback(\n",
        "            [Output('holo-display', 'figure'),\n",
        "             Output('probability-field', 'figure'),\n",
        "             Output('entanglement-web', 'figure'),\n",
        "             Output('temporal-wave', 'figure'),\n",
        "             Output('quantum-state-counter', 'value'),\n",
        "             Output('quantum-matrix', 'data'),\n",
        "             Output('quantum-consciousness', 'children')],\n",
        "            [Input('interval-update', 'n_intervals'),\n",
        "             Input('temporal-scale', 'value'),\n",
        "             Input('hyper-scale', 'value')],\n",
        "            [State('holo-display', 'relayoutData')]\n",
        "        )\n",
        "        def quantum_render_loop(n, temp_scale, hyper_scale, view_state):\n",
        "            self.temporal_window = temp_scale\n",
        "            self.hyper_scale = hyper_scale\n",
        "\n",
        "            quantum_batch = []\n",
        "            while not self.data_stream.empty():\n",
        "                quantum_batch.append(self.data_stream.get())\n",
        "\n",
        "            if quantum_batch:\n",
        "                for qstate in quantum_batch:\n",
        "                    self.quantum_fields['state_vectors'].append(qstate['state_vector'])\n",
        "                    self.document_universe.append({\n",
        "                        'text': qstate['document_text'],\n",
        "                        'metadata': qstate['metadata']\n",
        "                    })\n",
        "                self.quantum_fields['hyper_projection'] = self._hyper_project(\n",
        "                    self.quantum_fields['state_vectors']\n",
        "                )\n",
        "            else:\n",
        "                raise PreventUpdate\n",
        "\n",
        "            holo_fig = self._render_holo_space(view_state)\n",
        "            prob_fig = self._render_probability_field()\n",
        "            ent_fig = self.entanglement_web\n",
        "            temp_fig = self.temporal_wave\n",
        "            matrix_data, consciousness = self._analyze_quantum_state()\n",
        "\n",
        "            return (holo_fig, prob_fig, ent_fig, temp_fig,\n",
        "                    f\"{len(self.quantum_fields['state_vectors']):04d}\",\n",
        "                    matrix_data, consciousness)\n",
        "\n",
        "        app.run(debug=True, use_reloader=False)\n",
        "\n",
        "def quantum_holographic_visualizer(splits):\n",
        "    \"\"\"Main entry to the Quantum Holographic System\"\"\"\n",
        "    holo_system = QuantumHologram()\n",
        "\n",
        "    def quantum_feeder():\n",
        "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        docs = [{'text': doc.page_content, 'metadata': doc.metadata} for doc in splits]\n",
        "\n",
        "        # Calculate qubits needed for 384-dim embeddings\n",
        "        sample_emb = model.encode([\"sample\"])[0]\n",
        "        next_pow2 = 2 ** int(np.ceil(np.log2(len(sample_emb))))\n",
        "        num_wires = int(np.log2(next_pow2))\n",
        "        dev = qml.device(\"default.qubit\", wires=num_wires)\n",
        "\n",
        "        @qml.qnode(dev)\n",
        "        def hyper_encoder(text):\n",
        "            emb = model.encode([text], normalize_embeddings=True)[0]\n",
        "            qml.AmplitudeEmbedding(emb, wires=range(num_wires), normalize=True, pad_with=0.0)\n",
        "            return qml.state()\n",
        "\n",
        "        for doc in docs:\n",
        "            try:\n",
        "                state = hyper_encoder(doc['text'])\n",
        "                holo_system.data_stream.put({\n",
        "                    'state_vector': np.abs(state),\n",
        "                    'document_text': textwrap.shorten(doc['text'], 200),\n",
        "                    'metadata': doc['metadata']\n",
        "                })\n",
        "                time.sleep(0.1)\n",
        "            except Exception as e:\n",
        "                print(f\"Quantum Error: {str(e)}\")\n",
        "\n",
        "    Thread(target=quantum_feeder).start()\n",
        "    holo_system.launch_hologram()\n",
        "\n",
        "# Execute with your document splits\n",
        "quantum_holographic_visualizer(splits)"
      ],
      "metadata": {
        "id": "PkNj-d6bKK-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Simulate \"Ripple Propagation\" for Queries\n",
        "\n",
        "In this phase, the query is treated as a perturbation—represented as a wavepacket, $\\psi_q(x)$—that propagates through the semantic field. Each document chunk is modeled as a quantum-inspired wavefunction, $\\psi_d(x)$, which encodes its semantic features.\n",
        "\n",
        "**The following equation quantifies the squared overlap between the query and a document chunk:**\n",
        "\n",
        "$$\n",
        "\\boxed{\\Large \\boldsymbol{S = \\left| \\langle \\psi_q \\,|\\, \\psi_d \\rangle \\right|^2}}\n",
        "$$\n",
        "\n",
        "Here, \\( S \\) measures the degree of resonance between the query's wavepacket and the document chunk's wavefunction, with higher values indicating a stronger semantic match.\n",
        "\n",
        "As the query's \"ripple\" propagates, document chunks with the highest \\( S \\) values are prioritized, enabling a dynamic and context-aware retrieval of relevant information.\n"
      ],
      "metadata": {
        "id": "Fn_ZPQUtLgf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: QUANTUM-INSPIRED RIPPLE PROPAGATION SIMULATION\n",
        "def quantum_ripple_propagation(sub_queries, quantum_excitations):\n",
        "    print(\"\\n=== INITIATING QUANTUM RIPPLE PROPAGATION ===\")\n",
        "\n",
        "    # 1. Quantum Encoding of Sub-Queries\n",
        "    print(f\"\\nEncoding {len(sub_queries)} sub-queries into quantum states...\")\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Generate query embeddings with same parameters as documents\n",
        "    query_embeddings = model.encode(sub_queries,\n",
        "                                   normalize_embeddings=True,\n",
        "                                   convert_to_numpy=True)\n",
        "\n",
        "    # Pad to 512 dimensions (same as document encoding)\n",
        "    padded_queries = np.zeros((len(sub_queries), 512))\n",
        "    padded_queries[:, :384] = query_embeddings\n",
        "    complex_queries = padded_queries.astype(np.complex128)\n",
        "\n",
        "    # Configure quantum encoder (mirroring document setup)\n",
        "    dev = qml.device(\"default.qubit\", wires=9)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def query_encoder(state):\n",
        "        qml.AmplitudeEmbedding(features=state,\n",
        "                             wires=range(9),\n",
        "                             normalize=False)\n",
        "        return qml.state()\n",
        "\n",
        "    # Encode all sub-queries\n",
        "    query_states = []\n",
        "    for idx, query in enumerate(complex_queries):\n",
        "        state = query_encoder(query)\n",
        "        query_states.append(state)\n",
        "        if idx < 2:  # Show first 2 sub-query states\n",
        "            print(f\"\\nSub-query {idx+1} Quantum State:\")\n",
        "            print(f\"Vector Norm: {np.linalg.norm(state):.4f}\")\n",
        "            print(f\"First 5 Amplitudes: {state[:5]}\")\n",
        "\n",
        "    # 2. Quantum State Similarity Computation\n",
        "    print(\"\\nComputing Quantum State Overlaps...\")\n",
        "\n",
        "    # Convert to numpy arrays for vectorized computation\n",
        "    doc_states = np.array(quantum_excitations)  # Shape: (3393, 512)\n",
        "    query_states = np.array(query_states)       # Shape: (n_queries, 512)\n",
        "\n",
        "    # Compute all pairwise overlaps using quantum mechanical inner product\n",
        "    similarity_matrix = np.abs(doc_states @ query_states.T.conj())**2\n",
        "    print(f\"\\nSimilarity Matrix Shape: {similarity_matrix.shape}\")\n",
        "    print(\"(Documents x Queries) dimensional relationship\")\n",
        "\n",
        "    # 3. Ripple Propagation Analysis\n",
        "    print(\"\\nApplying Ripple Propagation Dynamics:\")\n",
        "    # Use geometric mean for multiplicative interference effects\n",
        "    aggregated_scores = np.prod(similarity_matrix, axis=1)**(1/len(sub_queries))\n",
        "\n",
        "    # Quantum-inspired normalization\n",
        "    max_score = np.max(aggregated_scores)\n",
        "    normalized_scores = (aggregated_scores / max_score)**2  # Probability amplification\n",
        "\n",
        "    print(\"\\nScore Statistics:\")\n",
        "    print(f\"Maximum Document Score: {np.max(normalized_scores):.4f}\")\n",
        "    print(f\"Minimum Document Score: {np.min(normalized_scores):.4f}\")\n",
        "    print(f\"95th Percentile: {np.percentile(normalized_scores, 95):.4f}\")\n",
        "\n",
        "    # 4. Relevance Thresholding\n",
        "    quantum_fluctuation = np.std(normalized_scores)\n",
        "    threshold = np.mean(normalized_scores) + 2*quantum_fluctuation\n",
        "    print(f\"\\nAutomatic Relevance Threshold: {threshold:.4f}\")\n",
        "\n",
        "    # 5. Results Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(normalized_scores, bins=50, alpha=0.7, color='purple')\n",
        "    plt.axvline(threshold, color='red', linestyle='--')\n",
        "    plt.title(\"Quantum-Inspired Score Distribution\")\n",
        "    plt.xlabel(\"Semantic Similarity Score\")\n",
        "    plt.ylabel(\"Document Count\")\n",
        "    plt.show()\n",
        "\n",
        "    # Return sorted indices and scores\n",
        "    sorted_indices = np.argsort(normalized_scores)[::-1]\n",
        "    print(\"\\nTop 5 Relevant Documents:\")\n",
        "    for i, idx in enumerate(sorted_indices[:5]):\n",
        "        print(f\"{i+1}. Document {idx} - Score: {normalized_scores[idx]:.4f}\")\n",
        "\n",
        "    print(\"\\n=== RIPPLE PROPAGATION COMPLETE ===\")\n",
        "    return normalized_scores, threshold"
      ],
      "metadata": {
        "id": "t6s8qz_6KK_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import spacy\n",
        "\n",
        "def calculate_sdi(splits, quantum_excitations):\n",
        "    \"\"\"Calculate Semantic Density Index for both quantum and traditional methods\"\"\"\n",
        "    print(\"\\n=== SEMANTIC DENSITY INDEX CALCULATION ===\")\n",
        "\n",
        "    # Extract document texts\n",
        "    documents = [doc.page_content for doc in splits]\n",
        "\n",
        "    # 1. Quantum SDI Calculation\n",
        "    print(\"Calculating Quantum SDI...\")\n",
        "    quantum_sdi = []\n",
        "    for state in quantum_excitations:\n",
        "        # Measure non-zero amplitude components above noise floor\n",
        "        significant_components = np.sum(np.abs(state) > 1e-3)\n",
        "        quantum_sdi.append(significant_components)\n",
        "\n",
        "    # 2. BERT SDI Calculation\n",
        "    print(\"Calculating BERT SDI...\")\n",
        "    bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    bert_embeddings = bert_model.encode(documents)\n",
        "    bert_sdi = []\n",
        "    for emb in bert_embeddings:\n",
        "        # Count dimensions with significant activation\n",
        "        bert_sdi.append(np.sum(np.abs(emb) > np.percentile(np.abs(emb), 90)))\n",
        "\n",
        "    # 3. TF-IDF SDI Calculation\n",
        "    print(\"Calculating TF-IDF SDI...\")\n",
        "    tfidf = TfidfVectorizer(max_features=5000)\n",
        "    tfidf_matrix = tfidf.fit_transform(documents)\n",
        "    tfidf_sdi = tfidf_matrix.getnnz(axis=1)\n",
        "\n",
        "    # 4. SpaCy-based Semantic Count\n",
        "    print(\"Calculating Linguistic SDI...\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    linguistic_sdi = []\n",
        "    for doc in nlp.pipe(documents, disable=[\"parser\"]):\n",
        "        # Count unique semantic entities and noun phrases\n",
        "        entities = len(set([ent.text.lower() for ent in doc.ents]))\n",
        "        nouns = len(set([token.text.lower() for token in doc if token.pos_ == \"NOUN\"]))\n",
        "        linguistic_sdi.append(entities + nouns)\n",
        "\n",
        "    return {\n",
        "        'quantum': np.array(quantum_sdi),\n",
        "        'bert': np.array(bert_sdi),\n",
        "        'tfidf': np.array(tfidf_sdi),\n",
        "        'linguistic': np.array(linguistic_sdi)\n",
        "    }\n",
        "\n",
        "def visualize_sdi_comparison(sdi_results):\n",
        "    \"\"\"Visualize SDI comparison across different methods\"\"\"\n",
        "    plt.figure(figsize=(12, 7))\n",
        "\n",
        "    methods = ['Quantum', 'BERT', 'TF-IDF', 'Linguistic']\n",
        "    data = [sdi_results['quantum'], sdi_results['bert'],\n",
        "            sdi_results['tfidf'], sdi_results['linguistic']]\n",
        "\n",
        "    # Boxplot configuration\n",
        "    box = plt.boxplot(data, patch_artist=True, labels=methods,\n",
        "                     showmeans=True, meanline=True)\n",
        "\n",
        "    # Color configuration\n",
        "    colors = ['#ff7f0e', '#1f77b4', '#2ca02c', '#d62728']\n",
        "    for patch, color in zip(box['boxes'], colors):\n",
        "        patch.set_facecolor(color)\n",
        "        patch.set_alpha(0.6)\n",
        "\n",
        "    plt.title(\"Semantic Density Index Comparison\", fontsize=14)\n",
        "    plt.ylabel(\"Semantic Concepts per Document\", fontsize=12)\n",
        "    plt.xlabel(\"Encoding Method\", fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add statistical annotations\n",
        "    for i, method in enumerate(methods):\n",
        "        plt.text(i+1, np.max(data[i])*1.02,\n",
        "                f\"μ={np.mean(data[i]):.1f} ± {np.std(data[i]):.1f}\",\n",
        "                ha='center', fontsize=10)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def perform_sdi_analysis(splits, quantum_excitations):\n",
        "    \"\"\"Full SDI analysis workflow\"\"\"\n",
        "    # Calculate SDI metrics\n",
        "    sdi_results = calculate_sdi(splits, quantum_excitations)\n",
        "\n",
        "    # Print statistical summary\n",
        "    print(\"\\n=== SDI STATISTICAL SUMMARY ===\")\n",
        "    for method, values in sdi_results.items():\n",
        "        print(f\"\\n{method.upper()} SDI:\")\n",
        "        print(f\" - Average: {np.mean(values):.1f}\")\n",
        "        print(f\" - Std Dev: {np.std(values):.1f}\")\n",
        "        print(f\" - Max: {np.max(values)}\")\n",
        "        print(f\" - Min: {np.min(values)}\")\n",
        "\n",
        "    # Visual comparison\n",
        "    visualize_sdi_comparison(sdi_results)\n",
        "\n",
        "    return sdi_results\n",
        "\n",
        "# Usage example (add to your existing code)\n",
        "sdi_results = perform_sdi_analysis(splits, quantum_excitations)"
      ],
      "metadata": {
        "id": "jlTqReurKLBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q5Z_j_lCKLDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xuTc7HmoKLFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bHTfomsDKLHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mB2e57lLKLJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3NxE7zjKLLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKFxIrAdKLNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F67yhi1KKLPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hduWLFXsKLRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pTihvMAbKLVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51Z99YqoKLYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkpWTvtNKLaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7hl9N_NKLcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M-mS9Jf9KLe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oYCYm6cXKLg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xa7gEsNhKLjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXcd38vlKLlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JOKX7EfCKLnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyfMaCzTKLpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}